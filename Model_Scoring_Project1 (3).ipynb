{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xLByKkvjbtW"
   },
   "source": [
    "# ***Importing the required packages and splitting the dataset into test and train to demonstrate the train_model and project_1_scoring functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "JipqmNvCdFBk"
   },
   "outputs": [],
   "source": [
    "#importing pandas package\n",
    "import pandas as pd\n",
    "#reading the data\n",
    "df = pd.read_csv(\"/content/SBA_loans_project_1.csv\")\n",
    "\n",
    "df_v1 = df.copy() #maintaining a copy of the dataframe\n",
    "\n",
    "#splitting the dataset into test and train to demonstrate the below functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBrXPzOjjs6m"
   },
   "source": [
    "# ***train_model function***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "G_p3DkSSCmjT"
   },
   "outputs": [],
   "source": [
    "#A Function which trains the model and returns the trained model path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def train_model(data):\n",
    "    \"\"\"\n",
    "    Train sample model and save artifacts\n",
    "    \"\"\"\n",
    "    #importing and installing the necessary packages\n",
    "    !pip install category_encoders\n",
    "    !pip install h2o\n",
    "    !pip install dill\n",
    "    from copy import deepcopy\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import pickle\n",
    "    import dill as pickle\n",
    "    import category_encoders as ce\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    \n",
    "    # Handling the missing values for string type columns\n",
    "    Handling_string_cols_missing = ['City','State','Bank','BankState','RevLineCr','LowDoc']\n",
    "    for col in Handling_string_cols_missing:\n",
    "      data[col].fillna(\"Missing\",inplace=True)\n",
    "    \n",
    "    #Handling Missing values in numerical columns-dropping those values\n",
    "    data.dropna(how='any',inplace=True)\n",
    "\n",
    "    # some data transformations\n",
    "    def df_manipulations(df):\n",
    "      #encoding the target column as a binary variable\n",
    "      MIS_Status_encoding = {\"MIS_Status\":{'P I F':0, 'CHGOFF': 1}}\n",
    "      df.replace(MIS_Status_encoding,inplace=True)\n",
    "      df['MIS_Status'] = df['MIS_Status'].astype(int)\n",
    "      #changing the datatype of zip\n",
    "      df['Zip'] = df['Zip'].astype(str)\n",
    "      #df transformations\n",
    "      #Converting the currency columns to float\n",
    "      df['DisbursementGross'] = df['DisbursementGross'].str.replace(\"'\", '').str.replace('$', '').str.replace(\",\", '').astype(float)\n",
    "      df['BalanceGross'] = df['BalanceGross'].str.replace(\"'\", '').str.replace('$', '').str.replace(\",\", '').astype(float)\n",
    "      df['GrAppv'] = df['GrAppv'].str.replace(\"'\", '').str.replace('$', '').str.replace(\",\", '').astype(float)\n",
    "      df['SBA_Appv'] = df['SBA_Appv'].str.replace(\"'\", '').str.replace('$', '').str.replace(\",\", '').astype(float)\n",
    "      #dropping the index column\n",
    "      df.drop('index',inplace=True,axis=1)\n",
    "      return df\n",
    "    data = df_manipulations(data)\n",
    "\n",
    "    #one hot encoding the categorical columns\n",
    "    ohe_columns = ['LowDoc','NewExist','UrbanRural']\n",
    "    #one hot encoding the categorical columns\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False) # New in version 1.2: sparse was renamed to sparse_output\n",
    "    data_ohe = ohe.fit_transform(data[ohe_columns])\n",
    "    cols_ohe = ohe.get_feature_names_out()\n",
    "    data_ohe = pd.DataFrame(data_ohe, columns=cols_ohe,index=data.index)\n",
    "    data.drop(columns=ohe_columns,inplace=True)\n",
    "    data = pd.concat([data,data_ohe],axis=1)\n",
    "\n",
    "    # target column\n",
    "    target_col = 'MIS_Status'\n",
    "    y = data[target_col]\n",
    "    \n",
    "    #woe encoding the categorical variables\n",
    "    woe_encoder = ce.woe.WOEEncoder()\n",
    "    #fitting the encoding to the train dataset\n",
    "    to_be_woe_transformed_cols = ['City','State','Zip','Bank','BankState','RevLineCr']\n",
    "    woe_cols = ['City_woe','State_woe','Zip_woe','Bank_woe','BankState_woe','RevLineCr_woe']\n",
    "    woe_encoder.fit(data[to_be_woe_transformed_cols], y)\n",
    "    #transforming the training dataset\n",
    "    data[woe_cols] =woe_encoder.transform(data[to_be_woe_transformed_cols])\n",
    "\n",
    "    #preparing final feature dataframe\n",
    "    final_features_cols = ['City_woe', 'State_woe', 'Zip_woe', 'Bank_woe', 'BankState_woe', 'NAICS', 'Term', 'NoEmp',\n",
    "       'NewExist_0.0','NewExist_1.0','NewExist_2.0','UrbanRural_0','UrbanRural_1','UrbanRural_2','CreateJob', 'RetainedJob', 'FranchiseCode',\n",
    "       'RevLineCr_woe','DisbursementGross', 'BalanceGross', 'GrAppv',\n",
    "       'SBA_Appv','LowDoc_0','LowDoc_1', 'LowDoc_A', 'LowDoc_C', 'LowDoc_Missing', 'LowDoc_N',\n",
    "       'LowDoc_R', 'LowDoc_S', 'LowDoc_Y','MIS_Status']\n",
    "    data_final = data[final_features_cols]\n",
    "    \n",
    "    #H2O part--------------------------------------------------------------\n",
    "    #intializing the h2o cluster\n",
    "    import h2o\n",
    "    from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "    h2o.init(max_mem_size = \"14G\")             #specify max number of bytes. uses all cores by default.\n",
    "    h2o.remove_all()  \n",
    "    \n",
    "    #saving the column names into a variable\n",
    "    col_list = list(data_final.columns)\n",
    "    #converting the pandas dataframe to H2o frame\n",
    "    train_h2o = h2o.H2OFrame(data_final,column_names = col_list)\n",
    "\n",
    "    predictors = train_h2o.col_names[:-1]     #last column is whethere loan is approved or not\n",
    "    response = target_col\n",
    "\n",
    "    ## For binary classification, response should be a factor\n",
    "    train_h2o[response] = train_h2o[response].asfactor()\n",
    "\n",
    "    ##adding engineered features\n",
    "    def cut_column(train_df, train,col,n_bins):\n",
    "    \n",
    "      only_col= train_df[col]                            #Isolate the column in question from the training frame\n",
    "      counts, breaks = np.histogram(only_col, bins=n_bins)   #Generate counts and breaks for our histogram\n",
    "      min_val = min(only_col)-1                          #Establish min and max values\n",
    "      max_val = max(only_col)+1\n",
    "      new_b = [min_val]                                  #Redefine breaks such that each bucket has enough support\n",
    "      for i in range(n_bins-1):\n",
    "          if counts[i] > 1000 and counts[i+1] > 1000:\n",
    "              new_b.append(breaks[i+1])\n",
    "      new_b.append(max_val)\n",
    "      names = [col + '_' + str(x) for x in range(len(new_b)-1)]  #Generate names for buckets, these will be categorical names\n",
    "      train[col+\"_cut\"] = train[col].cut(breaks=new_b, labels=names)\n",
    "\n",
    "    def add_features(train):\n",
    "      #pull train dataset into Python\n",
    "      train_df = train.as_data_frame(True)\n",
    "      #getting the first two digits of NAICS code - which define the industries.\n",
    "      train['NAICS_sector'] = train['NAICS'] // 10000\n",
    "      #Make categoricals for several columns\n",
    "      cut_column(train_df, train,\"Term\",50)\n",
    "      cut_column(train_df, train,\"NoEmp\",10)\n",
    "      cut_column(train_df, train,\"CreateJob\",10)\n",
    "      cut_column(train_df, train,\"RetainedJob\",10)\n",
    "      cut_column(train_df, train,\"DisbursementGross\",100)\n",
    "      cut_column(train_df, train,\"GrAppv\",100)\n",
    "      cut_column(train_df, train, \"SBA_Appv\",100)\n",
    "      #Add interaction columns for a subset of columns\n",
    "      interaction_cols1 = [\n",
    "                          \"Term_cut\",\n",
    "                          \"NoEmp_cut\",\n",
    "                          \"CreateJob_cut\",\n",
    "                          \"RetainedJob_cut\",\n",
    "                          \"DisbursementGross_cut\"\n",
    "                    ]\n",
    "      train_cols = train.interaction(factors=interaction_cols1,    #Generate pairwise columns\n",
    "                                    pairwise=True,\n",
    "                                    max_factors=1000,\n",
    "                                    min_occurrence=100,\n",
    "                                    destination_frame=\"itrain\")\n",
    "      \n",
    "      train = train.cbind(train_cols)                              #Append pairwise columns to H2OFrames\n",
    "      \n",
    "      return train\n",
    "  \n",
    "    train_h2o_v1  = add_features(train_h2o)\n",
    "    ##train the model with the best parameters\n",
    "    glm = H2OGeneralizedLinearEstimator(family='binomial',alpha=0.68,lambda_ = 4.557E-4,seed=123,standardize=True)\n",
    "    glm.train(x = predictors, y = response, training_frame = train_h2o_v1)\n",
    "\n",
    "    ##threshold for max F1\n",
    "    threshold = 0.3001702 ##took the threshold where validation data had max f1\n",
    "\n",
    "    \n",
    "    # save the model\n",
    "    model_path = h2o.save_model(model=glm, path=\"/content/sample_data/artifacts/mymodel\", force=True)\n",
    "    #shutting down the cluster\n",
    "    h2o.cluster().shutdown()\n",
    "\n",
    "    #opening a pickle file and saving the artifacts dict\n",
    "    artifacts_dict_file = open(\"/content/sample_data/artifacts/artifacts_dict_file.pkl\", \"wb\")\n",
    "    artifacts_dict = {\n",
    "        \"target_col\":target_col,\n",
    "        \"model_path\": model_path,  \n",
    "        \"threshold\": threshold,\n",
    "        \"ohe_cols\":ohe_columns,\n",
    "        \"woe_encoder\":woe_encoder,\n",
    "        \"Handling_missing_cols\": Handling_string_cols_missing,\n",
    "        \"feature_cols\":final_features_cols,\n",
    "        \"woe_columns_to_be_transformed\":to_be_woe_transformed_cols,\n",
    "        \"woe_columns\":woe_cols,\n",
    "        \"OneHotEncoder\":ohe\n",
    "        \n",
    "       }\n",
    "    #dumping the dictionary\n",
    "    pickle.dump(obj=artifacts_dict, file=artifacts_dict_file)\n",
    "    #closing the pickle file\n",
    "    artifacts_dict_file.close() \n",
    "\n",
    "    #opening a new pickle file for functions as the previous pickle file can't serialize functions and as well as artifacts_dict in it\n",
    "    functions_pkl_file =  open(\"/content/sample_data/artifacts/functions.pkl\", \"wb\")\n",
    "    pickle.dump(obj=df_manipulations,file=functions_pkl_file)\n",
    "    pickle.dump(obj=add_features,file=functions_pkl_file)  \n",
    "    functions_pkl_file.close()\n",
    " \n",
    "    return model_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dYxD2q7jzGr"
   },
   "source": [
    "# ***train_model function demonstration with training dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yHmNQvU7daLA",
    "outputId": "2d86909c-47a9-4173-e24d-3f35209f3bd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: category_encoders in /usr/local/lib/python3.9/dist-packages (2.6.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.2.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (0.5.3)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (0.13.5)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.22.4)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.4.4)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->category_encoders) (2022.7.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from statsmodels>=0.9.0->category_encoders) (23.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: h2o in /usr/local/lib/python3.9/dist-packages (3.40.0.2)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from h2o) (0.8.10)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from h2o) (2.27.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from h2o) (0.18.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->h2o) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->h2o) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->h2o) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->h2o) (3.4)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (0.3.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-87-f0ae9da835e2>:37: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['DisbursementGross'] = df['DisbursementGross'].str.replace(\"'\", '').str.replace('$', '').str.replace(\",\", '').astype(float)\n",
      "<ipython-input-87-f0ae9da835e2>:38: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['BalanceGross'] = df['BalanceGross'].str.replace(\"'\", '').str.replace('$', '').str.replace(\",\", '').astype(float)\n",
      "<ipython-input-87-f0ae9da835e2>:39: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['GrAppv'] = df['GrAppv'].str.replace(\"'\", '').str.replace('$', '').str.replace(\",\", '').astype(float)\n",
      "<ipython-input-87-f0ae9da835e2>:40: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['SBA_Appv'] = df['SBA_Appv'].str.replace(\"'\", '').str.replace('$', '').str.replace(\",\", '').astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"11.0.18\" 2023-01-17; OpenJDK Runtime Environment (build 11.0.18+10-post-Ubuntu-0ubuntu120.04.1); OpenJDK 64-Bit Server VM (build 11.0.18+10-post-Ubuntu-0ubuntu120.04.1, mixed mode, sharing)\n",
      "  Starting server from /usr/local/lib/python3.9/dist-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmptqkjxsga\n",
      "  JVM stdout: /tmp/tmptqkjxsga/h2o_unknownUser_started_from_python.out\n",
      "  JVM stderr: /tmp/tmptqkjxsga/h2o_unknownUser_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-21.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-21 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-21 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-21 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table th,\n",
       "#h2o-table-21 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-21 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-21\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>03 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.2</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>24 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_unknownUser_m8v5p7</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>14 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.16 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------\n",
       "H2O_cluster_uptime:         03 secs\n",
       "H2O_cluster_timezone:       Etc/UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.2\n",
       "H2O_cluster_version_age:    24 days\n",
       "H2O_cluster_name:           H2O_from_python_unknownUser_m8v5p7\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    14 Gb\n",
       "H2O_cluster_total_cores:    2\n",
       "H2O_cluster_allowed_cores:  2\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.16 final\n",
       "--------------------------  ----------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Interactions progress: |█████████████████████████████████████████████████████████| (done) 100%\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "H2O session _sid_90f0 closed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/sample_data/artifacts/mymodel/GLM_model_python_1680470792403_1'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#demonstrating the train_model function\n",
    "model_path_v1 = train_model(train)\n",
    "model_path_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKr4E28Mj9ib"
   },
   "source": [
    "# ***project_1_scoring function***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "XJ0FIxm2QoH9"
   },
   "outputs": [],
   "source": [
    "def project_1_scoring(data):\n",
    "    \"\"\"\n",
    "    Function to score input dataset.\n",
    "    \n",
    "    Input: dataset in Pandas DataFrame format\n",
    "    Output: Python list of labels in the same order as input records\n",
    "    \n",
    "    Flow:\n",
    "        - Load artifacts\n",
    "        - Transform dataset\n",
    "        - Score dataset\n",
    "        - Return labels\n",
    "    \n",
    "    \"\"\"\n",
    "    #installing the packages and importing them\n",
    "    !pip install category_encoders\n",
    "    !pip install h2o\n",
    "    !pip install dill\n",
    "    from copy import deepcopy\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import pickle\n",
    "    import category_encoders as ce\n",
    "    import dill as pickle\n",
    "    \n",
    "    '''Load Artifacts'''\n",
    "    artifacts_dict_file = open(\"/content/sample_data/artifacts/artifacts_dict_file.pkl\", \"rb\")\n",
    "    artifacts_dict = pickle.load(file=artifacts_dict_file)\n",
    "    artifacts_dict_file.close()\n",
    "\n",
    "    \n",
    "    #saving all the necessary variables from artifacts file\n",
    "    target_col = artifacts_dict['target_col']\n",
    "    model_path = artifacts_dict['model_path']\n",
    "    threshold = artifacts_dict['threshold']\n",
    "    ohe_columns = artifacts_dict['ohe_cols']\n",
    "    woe_encoder = artifacts_dict['woe_encoder']\n",
    "    Handling_string_cols_missing = artifacts_dict['Handling_missing_cols']\n",
    "    final_features_cols = artifacts_dict['feature_cols']\n",
    "    to_be_woe_transformed_cols = artifacts_dict['woe_columns_to_be_transformed']\n",
    "    woe_cols = artifacts_dict['woe_columns']\n",
    "    ohe = artifacts_dict['OneHotEncoder']\n",
    "    \n",
    "    # Handling the missing values for string type columns #Replacing the nulls in categorical columns with 'MISSING'\n",
    "    for col in Handling_string_cols_missing:\n",
    "      data[col].fillna(\"Missing\",inplace=True)\n",
    "  \n",
    "    #Handling Missing values in numerical columns-dropping those values\n",
    "    data.dropna(how='any',inplace=True)\n",
    "\n",
    "    #copying original data into a pandas dataframe\n",
    "    data_original = data.copy()\n",
    "    original_data_columns = list(data_original.columns)\n",
    "\n",
    "    '''Load functions pickle file'''\n",
    "    #some data transformations using df_manipulations function\n",
    "    functions_pkl_file =  open(\"/content/sample_data/artifacts/functions.pkl\", \"rb\")\n",
    "    data = pickle.load(file=functions_pkl_file)(data)\n",
    "    \n",
    "    #One hot encoding the categorical variables\n",
    "    data_ohe = ohe.transform(data[ohe_columns])\n",
    "    cols_ohe = ohe.get_feature_names_out()\n",
    "    data_ohe = pd.DataFrame(data_ohe, columns=cols_ohe,index=data.index)\n",
    "    data.drop(columns=ohe_columns,inplace=True)\n",
    "    data = pd.concat([data,data_ohe],axis=1)\n",
    "\n",
    "    # target column\n",
    "    y = data[target_col]\n",
    "    \n",
    "    #woe encoding the categorical variables\n",
    "    data[woe_cols] =woe_encoder.transform(data[to_be_woe_transformed_cols])\n",
    "\n",
    "    #preparing the final dataframe\n",
    "    data_final = data[final_features_cols]\n",
    "    \n",
    "    #H2O part--------------------------------------------------------------\n",
    "    #initializing the H2o cluster\n",
    "    import h2o\n",
    "    from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "    h2o.init(max_mem_size = \"14G\")             #specify max number of bytes. uses all cores by default.\n",
    "    h2o.remove_all()  \n",
    "    \n",
    "    #saving the column names in a variable\n",
    "    col_list = list(data_final.columns)\n",
    "    #converting the pandas dataframe to h2o frame\n",
    "    test_h2o = h2o.H2OFrame(data_final,column_names = col_list)\n",
    "\n",
    "    #adding the additional features\n",
    "\n",
    "    #last column is whethere loan is approved or not\n",
    "    predictors = test_h2o.col_names[:-1]     \n",
    "    response = target_col\n",
    "\n",
    "    ## For binary classification, response should be a factor\n",
    "    test_h2o[response] = test_h2o[response].asfactor()\n",
    "\n",
    "    ##adding the features\n",
    "    test_h2o_v1 = pickle.load(file=functions_pkl_file)(test_h2o)\n",
    "    functions_pkl_file.close()\n",
    "\n",
    "    #loading the trained model\n",
    "    glm = h2o.load_model(model_path)\n",
    "\n",
    "    #converting the original dataframe to pandas dataframe to concat it with the predicted probabilities\n",
    "    original_data_h2o = h2o.H2OFrame(data_original,column_names = original_data_columns) \n",
    "\n",
    "    #getting the predicted probabilities  \n",
    "    y_pred_proba = glm.predict(test_h2o_v1)\n",
    "\n",
    "    #concating the original frame with the predictions frame\n",
    "    results = original_data_h2o.cbind(y_pred_proba)\n",
    "\n",
    "    #coverting the resulting dataframe to pandas dataframe\n",
    "    results1 = results.as_data_frame()\n",
    "\n",
    "    #renaming the columns\n",
    "    some_dict = {'predict': 'predicted_class',\n",
    "                 'p0': 'probability_for_class_0_(PIF)',\n",
    "                 'p1': 'probability_for_class_1_(CHGOFF)'}\n",
    "    results1.rename(columns=some_dict, inplace=True)\n",
    "\n",
    "    #selecting the relevant columns\n",
    "    results2 = results1[['index','predicted_class','probability_for_class_0_(PIF)','probability_for_class_1_(CHGOFF)']]\n",
    "\n",
    "    #setting the index variable as index\n",
    "    results2.set_index('index', inplace=True)\n",
    "\n",
    "    return results2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOdViL01kC4k"
   },
   "source": [
    "# ***project_1_scoring function demonstration with test data ---> this returns the prediction dataframe***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SczWSdpg1H5T",
    "outputId": "d50562c9-8644-4dd7-f2b4-b045f536464d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: category_encoders in /usr/local/lib/python3.9/dist-packages (2.6.0)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.4.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.10.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (0.13.5)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.22.4)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (0.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->category_encoders) (2022.7.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from statsmodels>=0.9.0->category_encoders) (23.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: h2o in /usr/local/lib/python3.9/dist-packages (3.40.0.2)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from h2o) (0.18.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from h2o) (2.27.1)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from h2o) (0.8.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->h2o) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->h2o) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->h2o) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->h2o) (1.26.15)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (0.3.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-87-f0ae9da835e2>:37: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['DisbursementGross'] = df['DisbursementGross'].str.replace(\"'\", '').str.replace('$', '').str.replace(\",\", '').astype(float)\n",
      "<ipython-input-87-f0ae9da835e2>:38: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['BalanceGross'] = df['BalanceGross'].str.replace(\"'\", '').str.replace('$', '').str.replace(\",\", '').astype(float)\n",
      "<ipython-input-87-f0ae9da835e2>:39: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['GrAppv'] = df['GrAppv'].str.replace(\"'\", '').str.replace('$', '').str.replace(\",\", '').astype(float)\n",
      "<ipython-input-87-f0ae9da835e2>:40: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['SBA_Appv'] = df['SBA_Appv'].str.replace(\"'\", '').str.replace('$', '').str.replace(\",\", '').astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-23.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-23 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-23 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-23 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-23 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-23 .h2o-table th,\n",
       "#h2o-table-23 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-23 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-23\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 min 20 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.2</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>24 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_unknownUser_lgrq0f</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>13.99 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.16 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------\n",
       "H2O_cluster_uptime:         1 min 20 secs\n",
       "H2O_cluster_timezone:       Etc/UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.2\n",
       "H2O_cluster_version_age:    24 days\n",
       "H2O_cluster_name:           H2O_from_python_unknownUser_lgrq0f\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    13.99 Gb\n",
       "H2O_cluster_total_cores:    2\n",
       "H2O_cluster_allowed_cores:  2\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.16 final\n",
       "--------------------------  ----------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Interactions progress: |█████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-027b075b-261c-41bb-9eec-f5ccc9472c0c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>probability_for_class_0_(PIF)</th>\n",
       "      <th>probability_for_class_1_(CHGOFF)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>597590</th>\n",
       "      <td>0</td>\n",
       "      <td>0.698183</td>\n",
       "      <td>0.301817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540332</th>\n",
       "      <td>0</td>\n",
       "      <td>0.915363</td>\n",
       "      <td>0.084637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587189</th>\n",
       "      <td>0</td>\n",
       "      <td>0.850192</td>\n",
       "      <td>0.149808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631715</th>\n",
       "      <td>0</td>\n",
       "      <td>0.852126</td>\n",
       "      <td>0.147874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666323</th>\n",
       "      <td>0</td>\n",
       "      <td>0.866587</td>\n",
       "      <td>0.133413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802165</th>\n",
       "      <td>0</td>\n",
       "      <td>0.915846</td>\n",
       "      <td>0.084154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709022</th>\n",
       "      <td>0</td>\n",
       "      <td>0.983376</td>\n",
       "      <td>0.016624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706947</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999302</td>\n",
       "      <td>0.000698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653212</th>\n",
       "      <td>0</td>\n",
       "      <td>0.917970</td>\n",
       "      <td>0.082030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637090</th>\n",
       "      <td>0</td>\n",
       "      <td>0.706307</td>\n",
       "      <td>0.293693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161460 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-027b075b-261c-41bb-9eec-f5ccc9472c0c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-027b075b-261c-41bb-9eec-f5ccc9472c0c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-027b075b-261c-41bb-9eec-f5ccc9472c0c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        predicted_class  probability_for_class_0_(PIF)  \\\n",
       "index                                                    \n",
       "597590                0                       0.698183   \n",
       "540332                0                       0.915363   \n",
       "587189                0                       0.850192   \n",
       "631715                0                       0.852126   \n",
       "666323                0                       0.866587   \n",
       "...                 ...                            ...   \n",
       "802165                0                       0.915846   \n",
       "709022                0                       0.983376   \n",
       "706947                0                       0.999302   \n",
       "653212                0                       0.917970   \n",
       "637090                0                       0.706307   \n",
       "\n",
       "        probability_for_class_1_(CHGOFF)  \n",
       "index                                     \n",
       "597590                          0.301817  \n",
       "540332                          0.084637  \n",
       "587189                          0.149808  \n",
       "631715                          0.147874  \n",
       "666323                          0.133413  \n",
       "...                                  ...  \n",
       "802165                          0.084154  \n",
       "709022                          0.016624  \n",
       "706947                          0.000698  \n",
       "653212                          0.082030  \n",
       "637090                          0.293693  \n",
       "\n",
       "[161460 rows x 3 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class =project_1_scoring(test)\n",
    "predicted_class"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
